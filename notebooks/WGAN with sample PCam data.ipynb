{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: Umair Khan\n",
    "- Date: 15/07/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n",
    "from matplotlib import pyplot\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. WGAN supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "    # set clip value when initialized\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    # clip model weights to hypercube\n",
    "    def __call__(self, weights):\n",
    "        return backend.clip(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "    # get the config\n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}\n",
    "\n",
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generator, Critic & GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone critic model\n",
    "def define_critic(in_shape=(96, 96, 3)):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = ClipConstraint(0.01)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    # downsample to 48x48\n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    # downsample to 24x24\n",
    "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    # downsample to 12x12\n",
    "    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    # downsample to 6x6\n",
    "    model.add(Conv2D(512, (3,3), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    # scoring, linear activation\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    # compile model\n",
    "    #opt = RMSprop(lr=0.00005)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 1024 * 6 * 6\n",
    "    model.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((6, 6, 1024)))\n",
    "    # upsample to 6x6\n",
    "    model.add(Conv2DTranspose(512, (5,5), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    # upsample to 12x12\n",
    "    model.add(Conv2DTranspose(512, (5,5), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    # upsample to 24x24\n",
    "    model.add(Conv2DTranspose(512, (5,5), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    # upsample to 48x48\n",
    "    #model.add(Conv2DTranspose(512, (5,5), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(Conv2DTranspose(3, (5,5), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    # output 96x96x1\n",
    "    #model.add(Conv2D(3, (6,6), activation='tanh', padding='same', kernel_initializer=init))\n",
    "    return model\n",
    "\n",
    "# define the combined generator and critic model, for updating the generator\n",
    "def define_gan(generator, critic):\n",
    "    # make weights in the critic not trainable\n",
    "    critic.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the critic\n",
    "    model.add(critic)\n",
    "    # compile model\n",
    "    #opt = RMSprop(lr=0.00005)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(sample_type='both'):\n",
    "    data_path = \"E:\\\\project\\\\gan_pcam\\\\data\\\\train_sample\\\\\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    sample_paths = [join(data_path, 'positive'), join(data_path, 'negative')] if \\\n",
    "        sample_type == 'both' else [join(data_path, sample_type)]\n",
    "    \n",
    "    for sample_path in sample_paths:\n",
    "        image_paths = [f for f in listdir(sample_path) if isfile(join(sample_path, f))]\n",
    "        for img_path in image_paths:\n",
    "            img = Image.open(join(sample_path, img_path))\n",
    "            images.append(np.array(img))\n",
    "            labels.append(1 if 'positive' in sample_path else 0)\n",
    "            \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# load images\n",
    "def load_real_samples():\n",
    "    # load dataset\n",
    "    #(trainX, trainy), (_, _) = load_data()\n",
    "    trainX, trainy = load_sample_data(sample_type='positive')\n",
    "    # convert to float\n",
    "    X = trainX.astype('float32')\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = dataset[ix]\n",
    "    # generate class labels, -1 for 'real'\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels with 1.0 for 'fake'\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Checkpoint and Summary Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(epoch, g_model, latent_dim, n_samples=49):\n",
    "    # prepare fake examples\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = ((X * 127.5) + 127.5).astype('uint8')\n",
    "    # plot images\n",
    "    pyplot.figure(figsize=(20, 20))\n",
    "    for i in range(7 * 7):\n",
    "        # define subplot\n",
    "        pyplot.subplot(7, 7, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(X[i, :, :, :])\n",
    "    # save plot to file\n",
    "    filename1 = f'.\\\\WGAN with sample PCam data\\\\output\\\\generated_output_{epoch}.png'\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    filename2 = f'.\\\\WGAN with sample PCam data\\\\model\\\\g_model_{epoch}.h5'\n",
    "    g_model.save(filename2)\n",
    "    \n",
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "    # plot history\n",
    "    pyplot.figure(figsize=(12, 10))\n",
    "    pyplot.plot(d1_hist, label='crit_real')\n",
    "    pyplot.plot(d2_hist, label='crit_fake')\n",
    "    pyplot.plot(g_hist, label='gen')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig(f'.\\\\WGAN with sample PCam data\\\\plot_line_plot_loss.png')\n",
    "    pyplot.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96, 3)\n",
      ">Epoch:1 C1[-256.942], C2[-249.015] GL[254.666]\n",
      ">Epoch:2 C1[-904.879], C2[-854.475] GL[819.779]]15]\n",
      ">Epoch:3 C1[-1592.109], C2[-1619.909] GL[-969.912]1]\n",
      ">Epoch:4 C1[-2638.971], C2[-2656.806] GL[-1319.683]]\n",
      ">Epoch:5 C1[-3791.861], C2[-3792.909] GL[-2936.969]]\n",
      ">Epoch:6 C1[-5267.056], C2[-5198.860] GL[-5241.060]]\n",
      ">Epoch:7 C1[-6405.817], C2[-6383.061] GL[-1755.867]]\n",
      ">Epoch:8 C1[-8354.547], C2[-8055.554] GL[7841.894]]\n",
      ">Epoch:9 C1[-10133.038], C2[-9334.506] GL[9337.586]83]\n",
      ">Epoch:10 C1[-11999.361], C2[-10973.760] GL[10985.469]\n",
      ">Epoch:11 C1[-13972.513], C2[-12860.514] GL[12877.207]\n",
      ">Epoch:12 C1[-16047.083], C2[-14850.232] GL[14868.760]\n",
      ">Epoch:13 C1[-18215.445], C2[-16945.980] GL[16964.639]]\n",
      ">Epoch:14 C1[-20421.018], C2[-19119.559] GL[19146.549]]\n",
      ">Epoch:15 C1[-22866.027], C2[-21437.871] GL[21456.686]]\n",
      ">Epoch:16 C1[-25360.209], C2[-23853.127] GL[23885.736]]\n",
      ">Epoch:17 C1[-27929.955], C2[-26375.875] GL[26402.447]]\n",
      ">Epoch:18 C1[-30613.369], C2[-29015.025] GL[29037.170]]\n",
      ">Epoch:19 C1[-33209.930], C2[-31694.119] GL[31707.400]]\n",
      ">Epoch:20 C1[-36242.762], C2[-34545.883] GL[34577.195]]\n",
      ">Epoch:21 C1[-39229.957], C2[-37468.672] GL[37489.332]]\n",
      ">Epoch:22 C1[-42188.809], C2[-40442.961] GL[40489.254]]\n",
      ">Epoch:23 C1[-45453.137], C2[-43582.043] GL[43609.551]]\n",
      ">Epoch:24 C1[-48707.805], C2[-46784.688] GL[46816.508]]\n",
      ">Epoch:25 C1[-51883.168], C2[-50031.188] GL[50085.734]]\n",
      ">Epoch:26 C1[-53265.871], C2[-50762.801] GL[-23793.980]]\n",
      ">Epoch:27 C1[-57249.641], C2[-55862.438] GL[-31206.346]]\n",
      ">Epoch:28 C1[-60321.781], C2[-59419.871] GL[4923.217]3]]\n",
      ">Epoch:29 C1[-65643.023], C2[-63801.488] GL[63734.449]]\n",
      ">Epoch:30 C1[-69547.914], C2[-67624.820] GL[67672.406]]\n",
      ">Epoch:31 C1[-73464.727], C2[-71493.656] GL[71495.727]]\n",
      ">Epoch:32 C1[-77422.805], C2[-75387.734] GL[75440.430]]\n",
      ">Epoch:33 C1[-81507.383], C2[-79413.547] GL[79446.617]]\n",
      ">Epoch:34 C1[-85630.117], C2[-83413.516] GL[83511.156]]\n",
      ">Epoch:35 C1[-89871.172], C2[-87682.469] GL[87689.766]]\n",
      ">Epoch:36 C1[-94189.781], C2[-91898.188] GL[91970.203]]\n",
      ">Epoch:37 C1[-98569.703], C2[-96227.547] GL[96282.867]9]\n",
      ">Epoch:38 C1[-101372.773], C2[-99419.875] GL[99766.414]73]\n",
      ">Epoch:39 C1[-107324.422], C2[-104864.133] GL[104980.539]]\n",
      ">Epoch:40 C1[-111907.398], C2[-109340.703] GL[109507.281]]\n",
      ">Epoch:41 C1[-116692.023], C2[-114105.734] GL[114227.422]]\n",
      ">Epoch:42 C1[-121249.797], C2[-118509.664] GL[118785.945]]\n",
      ">Epoch:43 C1[-125483.875], C2[-122618.758] GL[80707.484]05]\n",
      ">Epoch:44 C1[-130693.266], C2[-128034.820] GL[-130508.016]]\n",
      ">Epoch:45 C1[-125514.805], C2[-131396.641] GL[127636.734]]]\n",
      ">Epoch:46 C1[-139534.359], C2[-137180.609] GL[80472.320]41]\n",
      ">Epoch:47 C1[-140219.391], C2[-139929.609] GL[-139660.531]]\n",
      ">Epoch:48 C1[-140509.969], C2[-138491.156] GL[-84219.086]9]\n",
      ">Epoch:49 C1[-149310.406], C2[-147705.562] GL[-127259.641]]\n",
      ">Epoch:50 C1[-157015.594], C2[-152977.469] GL[104994.602]0]\n",
      ">Epoch:51 C1[-164859.156], C2[-162017.438] GL[-97388.109]]]\n",
      ">Epoch:52 C1[-170852.375], C2[-168318.922] GL[123334.578]]\n",
      ">Epoch:53 C1[-177261.594], C2[-174819.250] GL[173955.547]]\n",
      ">Epoch:54 C1[-183263.750], C2[-180699.375] GL[180561.031]]\n",
      ">Epoch:55 C1[-189278.000], C2[-186584.016] GL[186517.250]]\n",
      ">Epoch:56 C1[-195250.484], C2[-192391.969] GL[192431.250]]\n",
      ">Epoch:57 C1[-201390.312], C2[-198440.688] GL[198529.766]]\n",
      ">Epoch:58 C1[-207598.156], C2[-204461.531] GL[204550.797]]\n",
      ">Epoch:59 C1[-213779.891], C2[-210566.891] GL[210731.906]]\n",
      ">Epoch:60 C1[-220157.891], C2[-216805.281] GL[216905.953]]\n",
      ">Epoch:61 C1[-226500.969], C2[-223096.250] GL[223210.594]]\n",
      ">Epoch:62 C1[-232767.250], C2[-229254.172] GL[229507.953]]\n",
      ">Epoch:63 C1[-239446.125], C2[-235881.312] GL[236161.328]]\n",
      ">Epoch:64 C1[-246040.406], C2[-242419.172] GL[242650.688]]\n",
      ">Epoch:65 C1[-252479.672], C2[-248976.391] GL[249119.078]]\n",
      ">Epoch:66 C1[-258736.688], C2[-255046.875] GL[255459.641]]\n",
      ">Epoch:67 C1[-266164.656], C2[-262565.312] GL[262731.875]]\n",
      ">Epoch:68 C1[-273042.719], C2[-269293.844] GL[269525.844]]\n",
      ">Epoch:69 C1[-279732.469], C2[-275774.906] GL[276087.938]]\n",
      ">Epoch:70 C1[-286705.625], C2[-282828.719] GL[283083.000]]\n",
      ">Epoch:71 C1[-294146.625], C2[-290157.281] GL[290373.812]]\n",
      ">Epoch:72 C1[-301128.375], C2[-297045.562] GL[297134.000]]\n",
      ">Epoch:73 C1[-306777.125], C2[-302844.781] GL[303491.938]]\n",
      ">Epoch:74 C1[-315568.625], C2[-311090.500] GL[311335.688]]\n",
      ">Epoch:75 C1[-323218.781], C2[-318520.438] GL[318839.750]]\n",
      ">Epoch:76 C1[-330651.969], C2[-325418.000] GL[325837.688]]\n",
      ">Epoch:77 C1[-337318.000], C2[-332192.906] GL[332579.938]]\n",
      ">Epoch:78 C1[-345809.812], C2[-340273.000] GL[340361.781]]\n",
      ">Epoch:79 C1[-348400.938], C2[-342257.062] GL[344439.938]]\n",
      ">Epoch:80 C1[-360082.312], C2[-355110.594] GL[354971.312]]\n",
      ">Epoch:81 C1[-368617.688], C2[-363277.688] GL[363491.625]]\n",
      ">Epoch:82 C1[-373607.562], C2[-366567.500] GL[369258.625]]\n",
      ">Epoch:83 C1[-383195.688], C2[-378974.469] GL[-340660.969]]\n",
      ">Epoch:84 C1[-391827.156], C2[-387902.062] GL[105386.977]]]\n",
      ">Epoch:85 C1[-400870.344], C2[-396528.938] GL[395567.438]]\n",
      ">Epoch:86 C1[-409496.906], C2[-404313.312] GL[404388.781]]\n",
      ">Epoch:87 C1[-418235.500], C2[-412665.812] GL[412759.219]]\n",
      ">Epoch:88 C1[-426861.062], C2[-420998.344] GL[421143.656]]\n",
      ">Epoch:89 C1[-431931.031], C2[-428633.688] GL[429008.188]]\n",
      ">Epoch:90 C1[-444082.812], C2[-438052.500] GL[438222.094]]\n",
      ">Epoch:91 C1[-452760.312], C2[-446783.656] GL[447066.219]]\n",
      ">Epoch:92 C1[-461812.156], C2[-455837.844] GL[455959.219]]\n",
      ">Epoch:93 C1[-469038.969], C2[-464350.719] GL[464641.500]]\n",
      ">Epoch:94 C1[-479811.281], C2[-473661.781] GL[473886.156]]\n",
      ">Epoch:95 C1[-488835.938], C2[-482621.375] GL[482991.906]]\n",
      ">Epoch:96 C1[-497493.344], C2[-491350.719] GL[491902.312]]\n",
      ">Epoch:97 C1[-507214.312], C2[-501371.125] GL[501380.219]]\n",
      ">Epoch:98 C1[-514932.781], C2[-510198.656] GL[510399.062]]\n",
      ">Epoch:99 C1[-525930.062], C2[-519688.812] GL[519976.094]]\n",
      ">Epoch:100 C1[-535325.438], C2[-529325.312] GL[529434.562]\n",
      ">Epoch:101 C1[-544751.188], C2[-538766.188] GL[539027.625]\n",
      ">Epoch:102 C1[-551020.438], C2[-547467.875] GL[547869.875]\n",
      ">Epoch:103 C1[-563850.188], C2[-558084.188] GL[558298.062]\n",
      ">Epoch:104 C1[-573760.438], C2[-568017.188] GL[568056.438]\n",
      ">Epoch:105 C1[-582705.562], C2[-577425.688] GL[577733.812]\n",
      ">Epoch:106 C1[-593595.938], C2[-587739.250] GL[587943.062]\n",
      ">Epoch:107 C1[-603547.688], C2[-597805.875] GL[598100.500]\n",
      ">Epoch:108 C1[-613507.312], C2[-607765.312] GL[607941.000]\n",
      ">Epoch:109 C1[-620665.125], C2[-617440.688] GL[617872.375]\n",
      ">Epoch:110 C1[-633704.688], C2[-628181.062] GL[628381.125]\n",
      ">Epoch:111 C1[-644258.812], C2[-638362.312] GL[638833.562]\n",
      ">Epoch:112 C1[-654506.250], C2[-648994.688] GL[649434.625]\n",
      ">Epoch:113 C1[-665252.625], C2[-659668.875] GL[659882.438]\n",
      ">Epoch:114 C1[-674123.188], C2[-669523.312] GL[670035.688]\n",
      ">Epoch:115 C1[-686212.188], C2[-680695.312] GL[680794.188]\n",
      ">Epoch:116 C1[-696844.500], C2[-691508.312] GL[691892.000]\n",
      ">Epoch:117 C1[-705275.250], C2[-701639.000] GL[702032.688]\n",
      ">Epoch:118 C1[-718281.000], C2[-713205.312] GL[713313.562]\n",
      ">Epoch:119 C1[-729685.000], C2[-724185.375] GL[724468.562]\n",
      ">Epoch:120 C1[-740462.625], C2[-735382.812] GL[735574.625]\n",
      ">Epoch:121 C1[-750675.750], C2[-746085.438] GL[746493.688]\n",
      ">Epoch:122 C1[-762651.875], C2[-757401.875] GL[757887.125]\n",
      ">Epoch:123 C1[-773843.438], C2[-768887.438] GL[769114.125]\n",
      ">Epoch:124 C1[-783090.812], C2[-778834.125] GL[779501.438]\n",
      ">Epoch:125 C1[-796432.562], C2[-791841.938] GL[792269.188]\n",
      ">Epoch:126 C1[-807639.000], C2[-803252.188] GL[803700.750]\n",
      ">Epoch:127 C1[-818624.625], C2[-814513.875] GL[815175.312]\n",
      ">Epoch:128 C1[-831249.312], C2[-826588.625] GL[826834.438]\n",
      ">Epoch:129 C1[-843089.375], C2[-838461.062] GL[838987.750]]\n",
      ">Epoch:130 C1[-854567.438], C2[-850308.125] GL[850552.812]]\n",
      ">Epoch:131 C1[-861811.062], C2[-860142.438] GL[860746.688]]\n",
      ">Epoch:132 C1[-878462.125], C2[-874151.562] GL[874389.875]]\n",
      ">Epoch:133 C1[-890550.688], C2[-886093.125] GL[886652.188]]\n",
      ">Epoch:134 C1[-899998.750], C2[-897515.000] GL[897649.000]]\n",
      ">Epoch:135 C1[-914456.500], C2[-910410.562] GL[910593.625]]\n",
      ">Epoch:136 C1[-927104.125], C2[-922989.625] GL[923699.188]]\n",
      ">Epoch:137 C1[-939577.875], C2[-935427.188] GL[935931.562]]\n",
      ">Epoch:138 C1[-951672.812], C2[-948206.562] GL[948525.750]]\n",
      ">Epoch:139 C1[-964455.188], C2[-960757.875] GL[961147.375]]\n",
      ">Epoch:140 C1[-976898.562], C2[-973394.125] GL[973771.312]]\n",
      ">Epoch:141 C1[-985886.750], C2[-983988.125] GL[984927.000]]\n",
      ">Epoch:142 C1[-1002079.375], C2[-998990.438] GL[999252.438]50]\n",
      ">Epoch:143 C1[-1015586.438], C2[-1011814.438] GL[1012322.375]]\n",
      ">Epoch:144 C1[-1028083.000], C2[-1024919.500] GL[1025328.000]]\n",
      ">Epoch:145 C1[-1041241.938], C2[-1038025.750] GL[1038262.562]]\n",
      ">Epoch:146 C1[-1051284.000], C2[-1050390.625] GL[1050734.875]]\n",
      ">Epoch:147 C1[-1066507.750], C2[-1063904.625] GL[1063916.625]]\n",
      ">Epoch:148 C1[-1080432.000], C2[-1077302.125] GL[1077472.250]]\n",
      ">Epoch:149 C1[-1093684.250], C2[-1090671.875] GL[1091458.500]]\n",
      ">Epoch:150 C1[-1107226.625], C2[-1104181.375] GL[1104972.500]]\n",
      ">Epoch:151 C1[-1120597.125], C2[-1118115.375] GL[1118570.875]]\n",
      ">Epoch:152 C1[-1128989.500], C2[-1126468.250] GL[1127560.250]]\n",
      ">Epoch:153 C1[-1147815.625], C2[-1145306.750] GL[1145413.500]]\n",
      ">Epoch:154 C1[-1161620.500], C2[-1159057.750] GL[1159387.000]]\n",
      ">Epoch:155 C1[-1175307.250], C2[-1172896.125] GL[1173480.875]]\n",
      ">Epoch:156 C1[-1187333.375], C2[-1186276.250] GL[1186775.125]]\n",
      ">Epoch:157 C1[-1203455.125], C2[-1200590.125] GL[1201733.750]]\n",
      ">Epoch:158 C1[-1217331.500], C2[-1214798.875] GL[1215518.500]]\n",
      ">Epoch:159 C1[-1231407.250], C2[-1229430.750] GL[1230050.375]]\n",
      ">Epoch:160 C1[-1243161.000], C2[-1241572.125] GL[1242762.875]]\n",
      ">Epoch:161 C1[-1258898.625], C2[-1257512.000] GL[1258142.375]]\n",
      ">Epoch:162 C1[-1274304.875], C2[-1272922.000] GL[1272969.375]]\n",
      ">Epoch:163 C1[-1288530.875], C2[-1287112.875] GL[1287121.375]]\n",
      ">Epoch:164 C1[-1303093.125], C2[-1301768.625] GL[1301615.750]]\n",
      ">Epoch:165 C1[-1317293.750], C2[-1316381.375] GL[1316495.125]]\n",
      ">Epoch:166 C1[-1324951.875], C2[-1326175.750] GL[1326544.125]]\n",
      ">Epoch:167 C1[-1345989.375], C2[-1345965.000] GL[1345910.625]]\n",
      ">Epoch:168 C1[-1361412.250], C2[-1360509.750] GL[1361059.375]]\n",
      ">Epoch:169 C1[-1376721.125], C2[-1375500.000] GL[1376171.875]]\n",
      ">Epoch:170 C1[-1391756.875], C2[-1390903.875] GL[1391435.500]]\n",
      ">Epoch:171 C1[-1406894.875], C2[-1406117.125] GL[1406479.000]]\n",
      ">Epoch:172 C1[-1422095.500], C2[-1421329.375] GL[1421598.500]]\n",
      ">Epoch:173 C1[-1428865.250], C2[-1428755.000] GL[792758.750]25]\n",
      ">Epoch:174 C1[-1408339.250], C2[-1407935.125] GL[-1196522.000]]\n",
      ">Epoch:175 C1[-1456002.375], C2[-1456749.750] GL[709163.250]0]]\n",
      ">Epoch:176 C1[-1477724.375], C2[-1479186.500] GL[1479457.000]]\n",
      ">Epoch:177 C1[-1494710.125], C2[-1496705.000] GL[1496876.875]]\n",
      ">Epoch:178 C1[-1510561.125], C2[-1513669.625] GL[1514338.000]]\n",
      ">Epoch:179 C1[-1526293.375], C2[-1530522.500] GL[1530376.000]]\n",
      ">Epoch:180 C1[-1543149.375], C2[-1544604.875] GL[1545468.875]]\n",
      ">Epoch:181 C1[-1559120.375], C2[-1560764.375] GL[1561355.250]]\n",
      ">Epoch:182 C1[-1574910.875], C2[-1576794.875] GL[1577593.375]]\n",
      ">Epoch:183 C1[-1591056.625], C2[-1593305.250] GL[1593251.500]]\n",
      ">Epoch:184 C1[-1608053.125], C2[-1609384.625] GL[1609798.500]]\n",
      ">Epoch:185 C1[-1623817.000], C2[-1626019.125] GL[1625987.750]]\n",
      ">Epoch:186 C1[-1640302.750], C2[-1641959.375] GL[1642546.875]]\n",
      ">Epoch:187 C1[-1657042.125], C2[-1658472.250] GL[1659141.000]]\n",
      ">Epoch:188 C1[-1673259.875], C2[-1675480.125] GL[1675672.750]]\n",
      ">Epoch:189 C1[-1689534.625], C2[-1691559.750] GL[1692089.000]]\n",
      ">Epoch:190 C1[-1706590.625], C2[-1708746.375] GL[1708833.875]]\n",
      ">Epoch:191 C1[-1722700.750], C2[-1725481.000] GL[1725846.625]]\n",
      ">Epoch:192 C1[-1740030.750], C2[-1741494.375] GL[1743043.250]]\n",
      ">Epoch:193 C1[-1733099.500], C2[-1745300.875] GL[1750950.625]]\n",
      ">Epoch:194 C1[-1770071.000], C2[-1773996.250] GL[1774992.250]]\n",
      ">Epoch:195 C1[-1789560.625], C2[-1792840.875] GL[1792926.625]]\n",
      ">Epoch:196 C1[-1806503.000], C2[-1810144.250] GL[1811011.250]]\n",
      ">Epoch:197 C1[-1824487.125], C2[-1827259.125] GL[1827998.750]]\n",
      ">Epoch:198 C1[-1841731.750], C2[-1845043.250] GL[1845254.750]]\n",
      ">Epoch:199 C1[-1859089.625], C2[-1861806.750] GL[1862568.625]]\n",
      ">Epoch:200 C1[-1876024.000], C2[-1879709.750] GL[1880535.125]]\n",
      ">Epoch:201 C1[-1894238.375], C2[-1897400.250] GL[1897789.500]]\n",
      ">Epoch:202 C1[-1888378.875], C2[-1900744.250] GL[1903829.500]]\n",
      ">Epoch:203 C1[-1924593.375], C2[-1927301.500] GL[1927266.500]]\n",
      ">Epoch:204 C1[-1945164.750], C2[-1949435.875] GL[1949458.000]]\n",
      ">Epoch:205 C1[-1963769.875], C2[-1967606.000] GL[1968318.750]]\n",
      ">Epoch:206 C1[-1981709.750], C2[-1986230.750] GL[1986975.625]]\n",
      ">Epoch:207 C1[-1999784.375], C2[-2004242.625] GL[2005304.875]]\n",
      ">Epoch:208 C1[-2017233.875], C2[-2022508.500] GL[2023417.000]]\n",
      ">Epoch:209 C1[-2036098.500], C2[-2040594.625] GL[2041945.625]]\n",
      ">Epoch:210 C1[-2054246.375], C2[-2059152.875] GL[2059811.750]]\n",
      ">Epoch:211 C1[-2072738.875], C2[-2077526.375] GL[2078498.875]]\n",
      ">Epoch:212 C1[-2066934.750], C2[-2073834.500] GL[2083014.375]]\n",
      ">Epoch:213 C1[-2107056.750], C2[-2112419.750] GL[2112709.250]]\n",
      ">Epoch:214 C1[-2126734.000], C2[-2131605.250] GL[2132662.250]]\n",
      ">Epoch:215 C1[-2144161.250], C2[-2147647.500] GL[2148942.250]]\n",
      ">Epoch:216 C1[-2164036.000], C2[-2169554.750] GL[2170075.750]]\n",
      ">Epoch:217 C1[-2182624.250], C2[-2188858.250] GL[2189608.500]]\n",
      ">Epoch:218 C1[-2202367.000], C2[-2207519.250] GL[2208002.750]]\n",
      ">Epoch:219 C1[-2220481.250], C2[-2226595.000] GL[2228338.000]]\n",
      ">Epoch:220 C1[-2209661.750], C2[-2211218.750] GL[1406052.625]0]\n",
      ">Epoch:221 C1[-2249182.250], C2[-2249225.250] GL[-2238463.500]]\n",
      ">Epoch:222 C1[-2239082.750], C2[-2267015.000] GL[1266803.625]]]\n",
      ">Epoch:223 C1[-2292143.500], C2[-2299453.250] GL[2298740.500]]\n",
      ">Epoch:224 C1[-2313002.250], C2[-2320057.250] GL[2319988.000]]\n",
      ">Epoch:225 C1[-2332981.250], C2[-2340139.000] GL[2340307.000]]\n",
      ">Epoch:226 C1[-2351427.750], C2[-2360135.250] GL[2360289.500]]\n",
      ">Epoch:227 C1[-2371921.750], C2[-2380234.250] GL[2381436.750]]\n",
      ">Epoch:228 C1[-2391499.250], C2[-2399682.750] GL[2400762.750]]\n",
      ">Epoch:229 C1[-2411251.250], C2[-2419659.000] GL[2420136.500]]\n",
      ">Epoch:230 C1[-2430108.000], C2[-2437921.000] GL[2439759.750]]\n",
      ">Epoch:231 C1[-2450693.250], C2[-2459369.750] GL[2460064.500]]\n",
      ">Epoch:232 C1[-2471401.000], C2[-2479960.500] GL[2480619.750]]\n",
      ">Epoch:233 C1[-2490178.750], C2[-2498602.750] GL[2500482.750]]\n",
      ">Epoch:234 C1[-2496596.750], C2[-2499106.500] GL[2514420.000]]\n",
      ">Epoch:235 C1[-2527622.250], C2[-2537458.500] GL[2537114.250]]\n",
      ">Epoch:236 C1[-2549985.750], C2[-2560960.250] GL[2560918.250]]\n",
      ">Epoch:237 C1[-2571329.500], C2[-2580612.500] GL[2582507.000]]\n",
      ">Epoch:238 C1[-2591883.000], C2[-2601946.000] GL[2602747.750]]\n",
      ">Epoch:239 C1[-2611709.750], C2[-2622028.000] GL[2623479.500]]\n",
      ">Epoch:240 C1[-2632590.250], C2[-2641787.000] GL[2642456.250]]\n",
      ">Epoch:241 C1[-2603111.000], C2[-2627036.000] GL[2647553.250]]\n",
      ">Epoch:242 C1[-2567036.750], C2[-2614609.250] GL[-2463747.000]]\n",
      ">Epoch:243 C1[-2239223.250], C2[-2580608.250] GL[-1479479.000]]\n",
      ">Epoch:244 C1[-2683400.000], C2[-2691459.750] GL[-2574517.250]]\n",
      ">Epoch:245 C1[-2713501.250], C2[-2726576.500] GL[-2633015.750]]\n",
      ">Epoch:246 C1[-2735089.250], C2[-2749489.500] GL[751983.875]0]]\n",
      ">Epoch:247 C1[-2762821.500], C2[-2777452.000] GL[2773900.250]]\n",
      ">Epoch:248 C1[-2787591.500], C2[-2802046.250] GL[2802022.250]]\n",
      ">Epoch:249 C1[-2810809.750], C2[-2824797.500] GL[2825252.000]]\n",
      ">Epoch:250 C1[-2833111.500], C2[-2846589.750] GL[2847797.000]]\n",
      ">Epoch:251 C1[-2854505.000], C2[-2869208.000] GL[2869986.750]]\n",
      ">Epoch:252 C1[-2876687.500], C2[-2892030.250] GL[2891055.750]]\n",
      ">Epoch:253 C1[-2899088.500], C2[-2913239.500] GL[2913640.250]]\n",
      ">Epoch:254 C1[-2920422.750], C2[-2934707.500] GL[2936229.250]]\n",
      ">Epoch:255 C1[-2942519.000], C2[-2957457.250] GL[2957543.750]]\n",
      ">Epoch:256 C1[-2964712.500], C2[-2980301.750] GL[2979064.000]]\n",
      ">Epoch:257 C1[-2986364.250], C2[-3001127.500] GL[3003046.250]]\n",
      ">Epoch:258 C1[-3008294.250], C2[-3023230.750] GL[3024730.750]]\n",
      ">Epoch:259 C1[-3023639.500], C2[-3037703.250] GL[3039479.750]]\n",
      ">Epoch:260 C1[-3051768.250], C2[-3067333.250] GL[3067740.000]]\n",
      ">Epoch:261 C1[-3074678.750], C2[-3089766.250] GL[3091097.000]]\n",
      ">Epoch:262 C1[-3097239.750], C2[-3113074.750] GL[3113405.250]]\n",
      ">Epoch:263 C1[-3119426.750], C2[-3135477.000] GL[3136151.500]]\n",
      ">Epoch:264 C1[-3142528.000], C2[-3158295.500] GL[3158713.000]]\n",
      ">Epoch:265 C1[-3163047.500], C2[-3178883.000] GL[3172124.250]]\n",
      ">Epoch:266 C1[-3153678.250], C2[-3154429.250] GL[1371675.500]0]\n",
      ">Epoch:267 C1[-3199018.250], C2[-3212548.250] GL[-3164955.250]]\n",
      ">Epoch:268 C1[-2974145.500], C2[-3087112.500] GL[-1188322.250]]\n",
      ">Epoch:269 C1[-3231293.750], C2[-3251220.000] GL[-2154569.250]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Epoch:270 C1[-3263274.250], C2[-3285083.750] GL[3283076.000]]\n",
      ">Epoch:271 C1[-3292423.750], C2[-3311980.250] GL[3312646.250]]\n",
      ">Epoch:272 C1[-3317852.750], C2[-3338231.500] GL[3338023.250]]\n",
      ">Epoch:273 C1[-3340739.000], C2[-3361717.500] GL[3362646.500]]\n",
      ">Epoch:274 C1[-3365827.500], C2[-3386159.500] GL[3385862.250]]\n",
      ">Epoch:275 C1[-3389163.500], C2[-3409550.750] GL[3411141.000]]\n",
      ">Epoch:276 C1[-3413424.000], C2[-3434363.250] GL[3434424.250]]\n",
      ">Epoch:277 C1[-3438932.500], C2[-3456892.250] GL[3458516.500]]\n",
      ">Epoch:278 C1[-3461696.000], C2[-3481393.250] GL[3483438.250]]\n",
      ">Epoch:279 C1[-3486485.750], C2[-3505093.000] GL[3506781.250]]\n",
      ">Epoch:280 C1[-3510147.750], C2[-3529271.000] GL[3531442.750]]\n",
      ">Epoch:281 C1[-3533050.250], C2[-3553948.000] GL[3554892.250]]\n",
      ">Epoch:282 C1[-3558153.500], C2[-3577483.000] GL[3578402.000]]\n",
      ">Epoch:283 C1[-3581313.250], C2[-3601453.250] GL[3603485.500]]\n",
      ">Epoch:284 C1[-3606013.250], C2[-3625874.000] GL[3627284.500]]\n",
      ">Epoch:285 C1[-3629757.500], C2[-3650853.000] GL[3652178.750]]\n",
      ">Epoch:286 C1[-3655079.000], C2[-3674458.750] GL[3676816.500]]\n",
      ">Epoch:287 C1[-3678905.500], C2[-3700099.750] GL[3700741.750]]\n",
      ">Epoch:288 C1[-3700529.750], C2[-3723602.500] GL[3724745.500]]\n",
      ">Epoch:289 C1[-3727748.500], C2[-3749295.500] GL[3750448.500]]\n",
      ">Epoch:290 C1[-3751927.500], C2[-3773685.000] GL[3775200.500]]\n",
      ">Epoch:291 C1[-3776096.750], C2[-3798595.750] GL[3800337.750]]\n",
      ">Epoch:292 C1[-3802468.500], C2[-3823861.750] GL[3825899.000]]\n",
      ">Epoch:293 C1[-3785613.250], C2[-3802552.250] GL[3838496.000]]\n",
      ">Epoch:294 C1[-3835446.500], C2[-3859641.500] GL[3859238.500]]\n",
      ">Epoch:295 C1[-3870743.750], C2[-3895821.250] GL[3895913.500]]\n",
      ">Epoch:296 C1[-3899064.250], C2[-3923289.000] GL[3922796.000]]\n",
      ">Epoch:297 C1[-3925569.250], C2[-3948924.750] GL[3948942.750]]\n",
      ">Epoch:298 C1[-3950533.750], C2[-3974822.250] GL[3976590.750]]\n",
      ">Epoch:299 C1[-3975544.500], C2[-4000741.750] GL[4001412.500]]\n",
      ">Epoch:300 C1[-4003091.250], C2[-4025758.000] GL[4028035.750]]\n"
     ]
    }
   ],
   "source": [
    "# train the generator and critic\n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=300, n_batch=64, n_critic=5):\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # lists for keeping track of loss\n",
    "    c1_hist, c2_hist, g_hist = [], [], []\n",
    "    c1_epoch, c2_epoch, g_epoch = [], [], []\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # update the critic more than the generator\n",
    "        c1_tmp, c2_tmp = [], []\n",
    "        for _ in range(n_critic):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update critic model weights\n",
    "            c_loss1 = c_model.train_on_batch(X_real, y_real)\n",
    "            c1_tmp.append(c_loss1)\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update critic model weights\n",
    "            c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
    "            c2_tmp.append(c_loss2)\n",
    "        # store critic loss\n",
    "        c1_hist.append(mean(c1_tmp))\n",
    "        c2_hist.append(mean(c2_tmp))\n",
    "        # prepare points in latent space as input for the generator\n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = -ones((n_batch, 1))\n",
    "        # update the generator via the critic's error\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        g_hist.append(g_loss)\n",
    "        # summarize loss on this batch\n",
    "        print(f'>Step:{i+1} C1[{c1_hist[-1]:.3f}], C2[{c2_hist[-1]:.3f}] GL[{g_loss:.3f}]\\r', end=\"\")\n",
    "        if (i+1) % bat_per_epo == 0:\n",
    "            print(f'>Epoch:{(i+1)//bat_per_epo} C1[{mean(c1_hist):.3f}], C2[{mean(c2_hist):.3f}] GL[{mean(g_hist):.3f}]')\n",
    "            c1_epoch.append(mean(c1_hist))\n",
    "            c2_epoch.append(mean(c2_hist))\n",
    "            g_epoch.append(mean(g_hist))\n",
    "            c1_hist, c2_hist, g_hist = [], [], []\n",
    "        # evaluate the model performance every 'epoch'\n",
    "        if (i+1) % (bat_per_epo * 1) == 0:\n",
    "            summarize_performance((i+1)//bat_per_epo, g_model, latent_dim)\n",
    "    # line plots of loss\n",
    "    plot_history(c1_epoch, c2_epoch, g_epoch)\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the critic\n",
    "critic = define_critic()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, critic)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "# train model\n",
    "train(generator, critic, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232345\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
